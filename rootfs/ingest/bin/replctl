#!/usr/bin/env python

# LSST Data Management System
# Copyright 2014-2015 AURA/LSST.
#
# This product includes software developed by the
# LSST Project (http://www.lsst.org/).
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the LSST License Statement and
# the GNU General Public License along with this program.  If not,
# see <http://www.lsstcorp.org/LegalNotices/>.

"""
Index table columns using replication service to Qserv

@author  Fabrice Jammes, IN2P3
"""

# -------------------------------
#  Imports of standard modules --
# -------------------------------
import argparse
from enum import Enum, auto
import sys

# ----------------------------
# Imports for other modules --
# ----------------------------
from qserv.ingest import Ingester
from qserv.jsonparser import DatabaseStatus
from qserv.metadata import ContributionMetadata
from qserv.queue import QueueManager
import qserv.util as util
from qserv.validator import Validator

class Task(str, Enum):
    REGISTER = "register"
    QUEUE = "queue"
    INGEST = "ingest"
    PUBLISH = "publish"
    INDEX = "index"
    VALIDATE = "validate"
    BENCHMARK = "benchmark"


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Create Qserv indexes (tables or secondary) "
                                     "using Qserv replication service")
    util.add_default_arguments(parser)
    subparsers = parser.add_subparsers(dest='task')

    # QUEUE step management
    parser_queue = subparsers.add_parser(Task.QUEUE, help="Load Qserv ingest database with input chunk files (i.e. contributions)")

    # REGISTER step management
    parser_register = subparsers.add_parser(Task.REGISTER, help="Initialize database and "
                                     "table inside Qserv replication service")
    parser_register.add_argument("--felis", type=str,
                            help=" A Felis schema file containing the table schema",
                            action=util.FelisAction)

    # INGEST step management
    parser_ingest = subparsers.add_parser(Task.INGEST, help="Launch Qserv replication service super-transactions "
                                     "driving chunk files ingest")
    parser_ingest.add_argument("--check", "-c", action='store_true',
                        help="Check if chunk file ingest has been performed successfully")
    parser_ingest.add_argument("--chunk-queue-fraction", "-f", type=int, metavar="FRACTION",
                        help="Fraction of chunk queue loaded per super-transaction")

    # PUBLISH step management
    parser_publish = subparsers.add_parser(Task.PUBLISH, help="Publish Qserv database")

    # INDEX step management
    parser_index = subparsers.add_parser(Task.INDEX,
                                         help="Create Qserv indexes (tables or secondary) using Qserv replication service")
    parser.add_argument("--secondary", "-s", action="store_true",
                        help="Create secondary index, and do not index tables")

    # VALIDATE step management
    parser_publish = subparsers.add_parser(Task.VALIDATE, help="Validate ingest for a database")

    # BENCHMARK step management
    parser_publish = subparsers.add_parser(Task.BENCHMARK, help="Benchmark ingest for a database")

    args = parser.parse_args()

    logger = util.get_default_logger(args.verbose)

    logger.debug("Ingest configuration: %s", args.config.__dict__)
    logger.debug("Task: %s", args.task)


    chunk_metadata = ContributionMetadata(args.config.path, args.config.servers)

    if args.task == Task.QUEUE:
        logger.debug("Queue")
        queue_manager = QueueManager(args.config.queue_url, chunk_metadata)
        queue_manager.load()
    elif args.task == Task.REGISTER:
        ingester = Ingester(chunk_metadata, args.config.replication_url)
        database_status = ingester.get_database_status()
        if database_status == DatabaseStatus.NOT_REGISTERED:
            ingester.database_register_and_config(args.felis)
        elif database_status == DatabaseStatus.REGISTERED_NOT_PUBLISHED:
            logger.warn("Skip current database registration: database has been registered previously")
        elif database_status == DatabaseStatus.PUBLISHED:
            logger.fatal("Fail current database registration: database has been published previously")
            sys.exit(1)
    elif args.task == Task.INGEST:
        queue_manager = QueueManager(args.config.queue_url, chunk_metadata)
        ingester = Ingester(chunk_metadata, args.config.replication_url, queue_manager)
        if args.check:
            ingester.check_supertransactions_success()
        else:
            ingester.ingest(args.chunk_queue_fraction)
    elif args.task == Task.PUBLISH:
        ingester = Ingester(chunk_metadata, args.config.replication_url)
        ingester.database_publish()
    elif args.task == Task.INDEX:
        ingester = Ingester(chunk_metadata, args.config.replication_url)
        ingester.index(args.secondary)
    elif args.task == Task.VALIDATE:
        validator = Validator(chunk_metadata, args.config.query_url, True)
        validator.query()
    elif args.task == Task.BENCHMARK:
        validator = Validator(chunk_metadata, args.config.query_url)
        if validator.benchmark():
            logger.info("Query results are identical to those expected")
        else:
            logger.fatal("Query results are not identical to those expected")
            sys.exit(1)
